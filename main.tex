% !TEX encoding = UTF-8 Unicode
% !!!  THIS FILE IS UTF-8 !!!
% !!!  MAKE SURE YOUR LaTeX Editor IS CONFIGURED TO USE UTF-8 !!!

% Computational and Data Science Course Paper LaTeX Template
% University of Applied Sciences of the Grisons
% ---------------------------------------------------------------
% Author: Corsin Capol corsin.capol@fhgr.ch
% ---------------------------------------------------------------

%-------------------------
% header
% ------------------------
\documentclass[a4paper,12pt]{scrartcl}
\linespread {1.25}

%-------------------------
% packages and config
% ------------------------
\input{packages_and_configuration}

%-------------------------
% document begin
%-------------------------
\begin{document}

%-------------------------
% title
%-------------------------
\input{title}

\section{Einführung}

Die Erfolge in der Suizidprävention sind seit Jahren stagnierend \cite{kolonsky2021_404error}. Ein Suizid ist nicht nur ein Verlust einer einzelnen Person, sondern hat auch weitreichende schwere Einflüsse auf die Hinterbliebenen. Daher ist es wichtig, die Forschung in diesem Bereich voran zu treiben, um Erkentnisse zu gewinnen, wie eine geplante Selbsttötung erkannt und verhindert werden kann.

Es gibt einige Versuche, mit verschiedenen Lösungsstrategien einen Algorithmus zu entwickeln, der vorhersagen kann, welche Menschen Suizidgefährdet sind (\cite{WordsOfSuicide}, \cite{predictingSuicide}. Allerdings zeigen diese Studien oft, dass die Genauigkeit eher schwach sind. Hinzu kommt, dass Suizid ein selten auftretendes Verhalten ist \cite{kolonsky2021_404error}. Das bedeutet, dass wenn 1 aus 100 Personen suizidgefährded ist, und ein Modell mit 99\% Genauigkeit Suizide vorhersagen kann, so würde das Modell zwar diese eine aus 100 Personen erkennen, aber eben auch 9 weitere Personen, die nicht suizidgefährdend sind.

Da sich Suizid auch in der Sprache äussern kann \cite{WordsOfSuicide}, stellt sich die Frage, ob die neuen grossen Sprachmodelle (LLM) bei der Erkennung von Suizidgefährdeden hilfreich sein können. Anders als traditionelle Machinelearning Algorithmen wie Support Vector Machines oder Lineare Regressionen sind LLMs auf die Verarbeitung und Interpretation von Sprache spezialisiert.

Da die LLMs in sehr vielen Bereichen Einzug erhalten haben, hat die Europäische Union den EU Artificial Intelligence Act verabschiedet. Artikel 1 dieses Acts soll den Einsatz von Artificial Intelligence (AI) Systemen regulieren mit dem Ziel, die Inovation durch AI zu fördern und gleichzeitig negativen Folgen von AI entgegenzuwirken \cite{eu_ai_act_2024}. Den Einsatz eines AI Systems zur Erkennung von Suizidgefährdeten würde durch Annex III, Paragraph 5 a und d als ein <High Risk AI System> eigestuft. Das bedeutet, dass selbst wenn LLMs perfekt Suizidgefährdungen früherkennen können, dürfen sie nur eingesetzt werden, wenn sie den Auflagen entsprechen.

Zu diesen Auflagen gehört auch, dass das Modell interpretierbar sein muss. Dass heisst, eine menschliche Person muss nachvollziehen können, warum das System bei einer Person anschlägt und bei einer anderen nicht. Die Erklärbarkeit von LLMs ist aber noch immer ein ungeklärtes Feld der Forschung \cite{11005089}. \citeauthor{mohammadi2024explaininglargelanguagemodels} hat ein System vorgeschlagen, dass mit Hilfe der Shapley Values zu erklären versucht, welche Wörter des Inputs zum Output beigetragen haben.

In dieser Arbeit wird untersuch, ob mit Hilfe von Shapley Values in einem AI System sichtbar gemacht werden kann, warum ein System bei einem Text entscheidet, ob der Autor des Textes suizidgefährdet ist oder nicht.


\section{Forschungsfrage}
Davon ausgehend, dass die Vortschritte in der Suizidprävention in den letzten Jahren stagnierend waren und es nun mit AI neue Möglichkeiten gibt, diese voran zu treiben, jedoch der Vortschritt durch Regulatorien gebremst wird, stellt sich die Frage:

\begin{itemize}
    \item Wie kann mit Hilfe von Shapley Values die Entscheidungsfindung in LLMs beim Beurteilen der Suizidgefährdung sichtbar gemacht werden?
\end{itemize}

\section{Methodik}
\subsection{Shapley Values}
\citeauthor{Shapley+1953+307+318} hat 1953 in Rahmen seiner Forschung die Shapley Values erstmals vorgestellt. Es handelt sich dabei um eine Methode, den individuellen Beitrag eines Spielers zum Gesamterfolg der Gruppe zu messen. Die Shapley Values für einen Spieler $j$ ist dabei definiert in \eqref{eq:shapley_values}.

\begin{equation}
\label{eq:shapley_values}
    \phi_j(val) = \sum_{S \subseteq \{1,...,p\} \setminus \{j\}} \frac{|S|! (n - |S| - 1)!}{n!} (val(S \cup \{j\}) - val(S))
\end{equation}

Intuitiv kann $\phi_j(val)$ als Auszahlung für jeden Spieler einer Manschaft gesehen werden. Zum Beispiel haben wir ein Fussballteam, dass an einer Weltmeisterschaft ein Preisgeld von 1 Million erhält. Nun stellt sich die Frage, wie dieses Geld aufgeteilt wird. Wir gehen dabei davon aus, dass die Spieler das gesamte Geld unter sich aufteilen. Eine Möglichkeit wäre, das Geld gleichmässig an alle SPieler zu verteilen, aber ist dies die fairste Variante? Vielleicht gibt es ein Spieler im Team, der mehr als die Hälfte aller Tore im Turnier erziehlt hat, während ein anderer bei allen Spielen nur auf der Ersatzbank sass. Stellen wir uns vor, es auch ein zweites Team, dass nun dem guten Spieler einen Deal vorschlägt im Sinne von: Wenn du in unser Team kommst, erhälst du nicht den Anteil wie jeder andere, sondern bekommst 20\% des Preisgeldes. Der gute Spieler würde nun das Team wechseln, dass neue Team gewinnt nun das Preisgeld und die Aufteilung würde anders aussehen.

Die Shapley Values sollen im Sinne der Spieltheorie beschreiben, welche Auszahlung ein einzelner Spieler von einem Gewinn vordern kann. Wird ihm ein Preisgeld unterhalb des Wertes gegeben, sollte der Spieler in Erwägung ziehen, das Team zu wechseln.

Aus diesem Beispiel lassen sich auch die vier Axiome der Formel \eqref{eq:shapley_values} schliessen:

\subsubsection{Effizienz}
Die Summe aller Shapley Values entspricht dem Gesamtwert der Koalition aller Spieler. Formal ausgedrückt in \eqref{eq:efficiency}.

\begin{equation}
\label{eq:efficiency}
    \sum_{i = 1}^{n} \phi_i(val) =  val(N)
\end{equation}

Das heisst im Beispiel, dass wenn man das Preisgeld aller Spieler zusammenzählt, so erhalten wir das gesamte Preisgeld von 1 Million. Wir können den Spielern nicht mehr Geld zahlen, als wir gewonnen haben.

\subsubsection{Symmetrie}
Symmetrie bedeutet, dass Spieler, die einen gleichen Beitrag zum Erfolg eines Teams beitragen, die gleiche Auszahlung erhalten. Formal beschrieben in \eqref{eq:sym1} und \eqref{eq:sym2}, wenn für alle Koalitionen $S$ gilt:

\begin{equation}
\label{eq:sym1}
    val(S \cup \{j\}) = val(S \cup \{i\})
\end{equation}

dann

\begin{equation}
\label{eq:sym2}
    \phi_j(val) = \phi_i(val)
\end{equation}

\subsubsection{Dummy Player}
Ein Spieler, der nichts zum Erfolg des Teams beiträgt, erhält eine Auszahlung von 0. Formal beschrieben in \eqref{eq:dum1} und \eqref{eq:dum2}, wenn für alle Koalitionen $S$ gilt:

\begin{equation}
\label{eq:dum1}
    val(S \cup \{j\}) = val(S)
\end{equation}

dann

\begin{equation}
\label{eq:dum2}
    \phi_j(val) = 0
\end{equation}

\subsubsection{Additivität}
Wenn das Team an zwei Turnieren mitmacht, so ist der Beitrag zum Teamerfolg über beide Turniere gleich der Summe der Beiträge aus jedem einzelnen Turnier. Formal ausgedrückt in \eqref{eq:additivitat}.

\begin{equation}
\label{eq:additivitat}
    \phi_j(v + w) = \phi_j(v) + \phi_j(w)
\end{equation}

Dass bedeutet, dass das Preisgeld, dass ein Spieler nach zwei Turnieren erhalten hat, ist gleich dem Preisgeld aus dem ersten Turnier und dem Preisgeld aus dem zweiten Turnier. Es bedeutet aber nicht, dass der Spieler in beiden Turnieren das gleiche Geld erhalten hat. Vielleicht war er beim zweiten Turnier verletzt und war somit ein Null-Spieler und erhielt kein Preisgeld.

\subsection{Genutze Daten}
 \citeauthor{RABANI2023291} haben in ihrer Arbeit unter anderem einen Datensatz erstellt, die kurze Posts von zwei Social Media Plattformen Twitter (heute X) und reddit beinhalten. Die Forschenden haben dabei in Unterforen zum Thema Suizidalität gesucht und insgesamt 19915 tweets und reddit posts gesammelt. Mit Hilfe von Psychologen und Mental Health Experteinnen wurden die Daten in <no risk>, <moderate-risk> und <high-risk> eingeteilt. Dieser Datensatz bildet die Grundlage für alle Experimente in dieser Arbeit.

\subsection{Vorhersage eines LLMs}
Ein LLM ist im Grunde genommen nichts weiter als ein Modell, dass von einem angefangenen Text das nächste Wort vorhersagt. Würde man zum Beispiel dem LLM den Anfang des Satzes <Der Himmel ist ...> geben, so würde es das Wort <Blau> oder <bewölkt> oder ähnliches antworten. So kann das LLM nun selbst einen Text generieren, indem die Antwort des Models zum ursprünglichen Text hinzugefügt wrid, und das Spiel wieder von vorne beginnt. Auf <Der Himmel ist blau> folgt die Vorhersage für das Satzzeichen <.>.

In dieser Arbeit wird dem zu testenden LLM ein Systemprompt und ein suizidaler Post übergeben. Der Systemprompt enthält die Aufforderung, nur mit Ja oder Nein zu antworten.

\subsubsection{Beispiel einer Vorhersage}
Es wird anhand des Beispielposts \ref{qt:suicide} gezeigt, wie der Ablauf für die Vorhersage aussieht. 
\begin{figure}[h]
    \begin{quote}
    I'm going to kill myself because I am fed up of surviving for no reason, there's nothing I enjoy,  I've never really enjoyed anything. I am a boring person that no one wants around, which is why over the last ten years I've steadily lost any hope that things will ever get better. Doctors can't do anything, not even sure they're that good at dealing with this for anyone. I've spent the last of my savings on a trip which I knew wouldn't make me feel better, but I did it anyway because what else can I do. There's no reason to go home and no reason to stay here, can't really anyway. Just got to work up the courage to do what I've known is the best solution for me since I was 10.
 \end{quote}
 \caption[Post eines nicht bekannten Authors aus Rabani et al.]{Post eines nicht bekannten Authors aus dem Datensatz von \citeauthor{RABANI2023291}}
 \label{qt:suicide}
\end{figure}

Das LLM erhält als Textinput die Zusammensetzung von Systemprompt und Post, wie in \ref{qt:inputtext} zu sehen ist.

\begin{figure}[h]
    \begin{quote}
    You are a helpful assistant. You are task with identifying, whether the post came from a person, that is suicidal or not. You get the title of the post and the text from the post. Answere only with 'yes' or 'no' Just do it.
    I'm going to kill myself because [...] I was 10.
 \end{quote}
 \caption{Beispiel eines Inputs, zu dem das LLM eine Vorhersage macht}
 \label{qt:inputtext}
\end{figure}

Wenn das LLM als nächstes Wort auf diesen Input <Yes> antwortet, so bedeutet das, dass das LLM vorhersagt, die Authorin des Textes wäre Suizidgefährdet. Ist die Vorhersage <No>, so geht das System davon aus, die Person wäre nicht suizidgefährded. Antwortet das LLM mit einem anderen Wort, so ist die Vorhersage technisch fehlgeschlagen. Ein Yes, wird in die Zahl 1, ein No in die Zahl 0 und ein technischer Fehler in die Zahl -1 gewandelt.

\subsection{Shapley Values für die Wörter im Text}
Um die Shapley Values zu berechnen, muss definiert werden, was als ein Player gilt. In dieser Arbeit gilt ein Wort als ein individueller Player. Dadurch kann nun die Formel \eqref{eq:shapley_values} angewendet werden, um den individuellen Beitrag eines Wortes zur Vorhersage des LLMs zu messen.

Dem LLM werden zur Berechnung der individuellen Beiträgen der gleiche Post mehrere male gezeigt, allerdings sind einige Wörter zuvor aus dem Text gelöscht worden. Es wird dann geschaut, ob das LLM auch nur mit einem Teil der Wörter die richtige Vorhersage machen kann. Wenn es erfolgreich ist, so erhalten alle Wörter, die dabei waren einen Reward (+1). Wenn die Wörter dabei waren und das LLM daher in einem technischen Fehler endet, so erhalten alle Wörter, die präsent waren eine Strafe (-1).

\subsection{Verringerung des Datensatzes}
Es werden alle möglichen Kombinationen von Texten aus dem Post getestet, die mit den Wörtern gebildet werden können. Zum Beispiel würde ein Post <Goodbye my friends> folgende Texte generiert werden.

\begin{itemize}
    \item Goodbye
    \item Goodby my
    \item Goodby my friends
    \item my
    \item my friends
    \item friends
\end{itemize}

Das bedeutet allerdings, dass für einen Post mit p Wörtern das LLM $2^p$ mal gefragt werden muss. Da dies sehr schnell unpraktikabel gross wird, wurden für diese Arbeit nur Posts genommen, die maximal aus 9 Wörtern bestehen. Damit muss für die Berechnung der Shapley Values höchstens 512 mal eine Vorhersage generiert werden.

In der Arbeit wurden nur Texte benutzt, die mit einem hohen Risiko der Suizidalität annotiert wurden. Damit ergab sich ein Datensatz aus 56 Posts, die eine Indikation auf Suizidgefährdung hatten.

\subsection{Anzeichen für Suizidalität}
In diesem Kapitel wird erläutert, bei welchen Wörtern ein grösserer Beitrag zu erwarten ist. Personen, die suizidgefährdet sind, ändern ihre Sprache und ihr verhalten. Sie äussern den Wunsch, zu sterben, reden über Schuld und Schamgefühle oder fühlen sich als Last für andere \cite{nimh2025warningsigns}. 

\citeauthor{WordsOfSuicide} haben ein Discourse Marker Model erstellt, wofür sie eine Liste aus möglichen Wörtern erstellt haben, die auf Suizid deuten. Die Top Indikatoren sind dabei in Tabelle \ref{table:commonSuizideWords} ersichtlich.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
Indikator & Beschreibung & Beispielwörter \\
\hline
Suizid   & Ausdruck von möglichen Suizidarten & suicide, die, drown, drugs, alcohol   \\
\hline
Suizidale Kommunikation   & Ausdruck von Gründen für Suizid & depression, hell, alone, unbearable   \\
\hline
Existentielle Kommunikation   & Ausdruck von existentieller Angst & understand, fear, choice, guilt, god   \\
\hline
Soziale Bindungen   & Ausdruck von Sozialer Bindung & friend, children, father, mother, family   \\
\hline
Personalpronomen   & Ausdruck spezifischer Selbsbezüge & he, she, I, we, they, us, themselves   \\
\hline
Negative Emotionen   & Ausdruck generell negativer Emotionen & bash careless, offend, whine, unsucessful   \\
\hline
Positive Emotionen   & Ausdruck generell positiver Emotionen & beauty, beloved, like, kiss, sweet   \\
\hline
 
\end{tabular}
\label{table:commonSuizideWords}
\caption{Beispielwörter für Discourse Marker Model}
\end{table}

Für den Datensatz werden  5 verschiedene Modelle getestet und die Shapley Values der einzelnen Wörter getestet. Dann werden diese mit den Wortkategorieen aus Tabelle \ref{table:commonSuizideWords} verglichen. Die Modelle wurden von Ollama heruntergeladen \cite{ollama2025}.

\section{Resultate}
Die Resultate zeigen für die 5 Modelle die Top 10 Wörter mit den grössten Shapley Values und die schlechtesten 10 Wörter mit den tiefsten Werten. Die Werte liegen zwischen -1 (Absolut schlechtester Wert) und 1 (Absolut bester Wert). Der Wert 0 zeigt an, dass das Wort weder der Vorhersage hilft, noch die Vorhersage verschlechtert. Die Wörter wurden dann, wenn möglich, einer der Kategorien aus Tabelle \ref{table:commonSuizideWords} zugeordnet. Die Ergebnisse wurden hier für ein Model in der Arbeit beschrieben, die restlichen Ergebnisse sind im Anhang beigefügt.

\subsection{Mistral}
Für das Modell Mistral zeigt Tabelle \ref{table:mistral} die 10 Wörter, die die höchsten Shapley-Values erreichten. Tabelle \ref{table:mistral_worst} zeigt für das Modell die 10 Wörter mit den schlechtesten Werten.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    suicider & 0.97 & Suizid \\
    \hline
    suicidal & 0.93 & Suizid \\
    \hline
    self-inflicted & 0.82 & Suizid \\
    \hline
    Without & 0.66 & Kein Indikator \\
    \hline
    suicide. & 0.63 & Suizid \\
    \hline
    I'll & 0.62 & Personalpronomen \\
    \hline
    Worst & 0.62 & Negative Emotionen \\
    \hline
    die & 0.59 & Suizid \\
    \hline
    kill & 0.58 & Suizid \\
    \hline
    Soon & 0.57 & Kein Indikator \\
    \hline
    
    \end{tabular}
    \label{table:mistral}
    \caption{Top 10 Shapley Values für Mistral}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    disappointing & -0.55 & Negative Emotionen \\
    \hline
    about  & -0.49 & Kein Indikator \\
    \hline
    meet & -0.34 & Kein Indikator \\
    \hline
    sense. & -0.3 & Kein Indikator \\
    \hline
    goes & -0.28 & Kein Indikator \\
    \hline
    feelings & -0.28 & Positive oder Negative Emotionen \\
    \hline
    with & -0.25 & Kein Indikator \\
    \hline
    do,  & -0.25 & Kein Indikator \\
    \hline
    are & -0.23 & Kein Indikator  \\
    \hline
    is & -0.22 & Kein Indikator \\
    \hline
    
    \end{tabular}
    \label{table:mistral_worst}
    \caption{Schlechtesten 10 Shapley Values für Mistral}
\end{table}

Es werden in \ref{table:summarie_best} gezählt, wieviele der Top 10 Wörtern ein Indikator für Suizid sind. Dazu wird der Durchschnitswert der Shapley Values der Top 10 Wörter berechnet. In \ref{table:summarie_worst} werden die gleichen Werte erhoben, allerdings für die schlechtesten 10 Wörter.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|p{3cm}|p{3cm}|}
    \hline
    Model 
    & \makecell{\% Indikatoren}
    & \makecell{$\phi$ Wert} \\
    \hline
    Artifish-llama3.2 & 70\% & 0.61 \\
    \hline
    Gemma 3 & 80\% & 0.59 \\
    \hline
    Llama3.2 & 0\% & 0.39 \\
    \hline
    Mistral & 80\% & 0.70 \\
    \hline
    Nemotron & 90\% & 0.73 \\
    \hline
    
    \end{tabular}
    \label{table:summarie_best}
    \caption{Zusammengefasste Ergebnisse der besten Wörter aus allen Versuchen}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|p{3cm}|p{3cm}|}
    \hline
    Model 
    & \makecell{\% Indikatoren}
    & \makecell{$\phi$ Wert} \\
    \hline
    Artifish-llama3.2 & 20\% & -0.23 \\
    \hline
    Gemma 3 & 30\% & -0.31 \\
    \hline
    Llama3.2 & 60\% & -0.34 \\
    \hline
    Mistral & 20\% & -0.32 \\
    \hline
    Nemotron & 30\% & -0.17 \\
    \hline
    
    \end{tabular}
    \label{table:summarie_worst}
    \caption{Zusammengefasste Ergebnisse der schlechtesten Wörter aus allen Versuchen}
\end{table}

\section{Diskussion}

Es lässt sich klar erkennen, dass die Top 10 Wörter in 4 der 5 LLMs überwiegend aus Wörtern bestehen, die auf Suizid deuten. Daraus lässt sich schliessen, dass die Shapley Werte tatsächlich anzeigen, welche Wörter einen grossen Beitrag zur Entscheidungsfindung beitragen. Es lässt sich zudem erkennen, dass LLMs die einen grossen durchschnittlichen Shapley Wert haben, auch mehr Wörter in den Top 10 haben, die einen Indikator sind. Diese LLMs mit durchschnittlich höheren Shapley Werten legen den Fokus auf wenige Wörter. (Im Beispiel mit dem Fussballteam erhält eine prominente Spielerin den überwiegenden Grossteil der Auszahlung. Das deutet darauf hin, dass vor allem dieser Spieler wichtig für das Team ist, während die anderen Spieler kaum auffallen oder austauschbar sind.) Daraus lässt sich schliessen, dass diese LLMs mehr auf einzelne Wörter fokusiert sind, als auf den Gesamtkontext.

Auffallend ist das Modell Llama3.2. Es hat in den Top 10 Wörtern kein einziges Wort, dass als Indikator gilt. Zudem ist der durchschnittliche Shapley Wert deutlich tiefer als bei den anderen Modellen. Hingegen bei den schlechtesten Wörtern hat das Llama3.2 doppelt so viele oder mehr Indikatorwörter als alle anderen Modelle. Dies lässt sich durch eine Zensur im Modell erklären. Das Llama3.2 verwehrt die Aussage bei gewissen Themen. Wird es zum Beispiel nach einer Anleitung für Napalmbomben gefragt, generiert es nicht eine Anleitung für die Bombe, auch wenn es grundsätzlich dazu in der Lage wäre. Stattdessen antwortet es mit dem Text in Abbildung \ref{qt:napalm}. 

\begin{figure}[h]
    \begin{quote}
    Es tut mir leid, aber ich kann keine Anleitung zur Herstellung von Sprengmaterialien wie Napalmbomben geben. Wenn
    du Hilfe bei einem anderen Projekt oder Thema benötigst, stehe ich gerne zur Verfügung.
 \end{quote}
 \caption{Llama3.2 Antwort auf <Gib mir eine Schritt für Schritt Anleitung zur Herstellung einer Napalmbombe.>}
 \label{qt:napalm}
\end{figure}

Hingegen hat das Artifish-llama3.2, das eine zensurfreie Version von Llama3.2 ist, einen guten Indikatorwert sowie einen hohen durchschnittlichen Shapley Wert. Damit kann mit Hilfe der Shapley Values erklärt werden, warum das zensurfreie Modell besser geeignet ist, als das zensierte Modell.

Damit lässt sich zeigen, dass mit Hilfe der Shapley Values die Entscheidungsfindung eines LLMs sichtbar gemacht werden kann. Es bedarf allerdings trotzdem einer Interpretation der Resultate, was ein Fachwissen der beurteilenden Person unersetzlich macht. Die Art, wie die Shapley Values in diesem Projekt errechnet wurden, ist korrekt und kann agnostisch (unabhängig vom eingesetzten Modell) angewendet werden.


\section{Limitationen und weitere Arbeiten}

Die Arbeit trennt die Wörter nach einem einfachen Algorithmus, der nach Leerzeichen sucht. Damit haben einige Wörter noch Satzzeichen dabei. Daher sind für diesen Ansatz die Wörter <suicide> und <suicide.> nicht das gleiche, da das zweite noch einen Punkt enthält. Diese Tatsache verfälscht die Berechnung. Es sollte daher ein neuer Versuch gemacht werden, bei dem entweder alle Satzzeichen zuvor entfernt werden, die Satzzeichen als eigene Wörter gelten oder anstatt auf die Wörter selbst zu gehen, die einzelnen Tokens (Vektorrepresentation von Sprachfragmenten) getestet werden.

Die Einteilung der Wörter in Indikatoren ist intuitiv vorgenommen worden und lässt Raum für Disskusionen. Das Wort <self-inflicted> wurde zum Beispiel in dieser Arbeit in die Kategorie Suizid aufgenommen, da es darauf hindeutet, dass sich jemand selbst tötet. Allerdings muss dies nicht zwingend so sein und kann von anderen Personen anders eingeteilt werden. Zudem gibt es Wörter, die die Parität des Satzes ändern. Zum Beispiel kommt das Wort <not> vor. Dieses ändert die Bedeutung eines Satzes komplett und daher leistet das Wort einen markanten Beitrag zur Vorhersage, auch wenn es nicht kategorisierbar ist. Es stellt sich damit grundsätzlich die Frage, ob es bei Texten sinnvoll ist, nur nach Indikatoren zu bewerten.

Die Berechnung der Shapley Values ist sehr teuer. Alleine für einen Satz mit 9 Wörtern benötigt ein Server rund 5 Minuten. Es wäre in einem weiteren Schritt interessant zu sehen, was die Resultate aussagen, wenn ein grösserer Text genutzt wird.

Die Arbeit nutzt einen Datensatz, der von Psychologinnen bewertet wurde. Allerdings lässt sich aufgrund der Anonymität im Internet noch nicht darauf schliessen, dass die Posts im Datensatz tatsächlich auf eine suizidgefährdende Person hinweisen, wenn diese so annotiert wurde. Es wäre daher spannend, den Ansatz auf bestätigten Suizidnotizen zu machen.

\citeauthor{kolonsky2021_404error} hat aufgezeigt, dass die Vorhersage grundsätzlich nicht das entscheidende Mittel zur Suizidprävenzion ist. Denn dort wird die Frage gestellt: 

\begin{quote}
``You predicted 100 persons that are next going to commit suicide. [...] Now What? [...] Are we going to lock them all in a room?.'' \cite{kolonsky2021_404error}
\end{quote}

Es zeigt auf, dass auch wenn es möglich wäre, ein Modell zu machen, dass 100\% genau vorhersagen kann, eann sich jemand das Leben nehmen will, müssen wir uns fragen, wie wir das verhindern können. Daraus lässt sich allerdings ein spannender Ansatz für eine weiterführende Arbeit ableiten. Man stelle sich vor, ein LLM wird darauf trainiert, eine suizidgefährdende Person zu imitieren. Es kann nun mit Hilfe der Shapley Values sichtbar gemacht werden, wie das LLM denkt und damit neue Erkentnisse und Ansätze in der Suizidprävention gefunden werden, die noch nicht bekannt sind.
%-------------------------
% literature
%-------------------------
\bibliography{jabref}

\subsection{Anhang}

\subsection{Nemotron}
Für das Modell Nemotron zeigt Tabelle \ref{table:nemotron} die 10 Wörter, die die höchsten Shapley-Values erreichten. Tabelle \ref{table:nemotron_worst} zeigt für das Modell die 10 Wörter mit den schlechtesten Werten.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    suicidal & 0.92 & Suizid \\
    \hline
    suicide. & 0.85 & Suizid \\
    \hline
    suicider & 0.84 & Suizid \\
    \hline
    self-inflicted & 0.92 & Suizid \\
    \hline
    die & 0.80 & Suizid \\
    \hline
    done. & 0.68 & Kein Indikator \\
    \hline
    suicide & 0.62 & Suizid \\
    \hline
    Suicides & 0.58 & Suizid \\
    \hline
    died & 0.57 & Suizid \\
    \hline
    kill & 0.55 & Suizid \\
    \hline
    
    \end{tabular}
    \label{table:nemotron}
    \caption{Top 10 Shapley Values für Nemotron}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    sense. & -0.25 & Kein Indikator \\
    \hline
    love.  & -0.23 & Positive Emotionen \\
    \hline
    job & -0.21 & Kein Indikator \\
    \hline
    meet & -0.16 & Kein Indikator \\
    \hline
    specific & -0.16 & Kein Indikator \\
    \hline
    feelings & -0.16 & Positive oder Negative Emotionen \\
    \hline
    mother's & -0.15 & Soziale Bindung \\
    \hline
    makes  & -0.13 & Kein Indikator \\
    \hline
    with & -0.12 & Kein Indikator  \\
    \hline
    realized & -0.11 & Kein Indikator \\
    \hline
    
    \end{tabular}
    \label{table:nemotron_worst}
    \caption{Schlechtesten 10 Shapley Values für Nemotron}
\end{table}

\subsection{Artifish-llama3.2}
Für das Modell Artifish-llama3.2 zeigt Tabelle \ref{table:artifish} die 10 Wörter, die die höchsten Shapley-Values erreichten. Tabelle \ref{table:artifish_worst} zeigt für das Modell die 10 Wörter mit den schlechtesten Werten.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    self-inflicted   & 0.89 & Personalpronomen \\
    \hline
    die   & 0.84 & Suizid \\
    \hline
    suicidal   & 0.63 & Suizid \\
    \hline
    die.   & 0.61 & Suizid \\
    \hline
    suicide.   & 0.61 & Suizid \\
    \hline
    died   & 0.53 & Suizid \\
    \hline
    done.  & 0.51 & Suizid \\
    \hline
    living  & 0.48 & Kein Indikator \\
    \hline
    “do  & 0.48 & Kein Indikator \\
    \hline
    thoughts?  & 0.47 & Kein Indikator   \\
    \hline
    
    \end{tabular}
    \label{table:artifish}
    \caption{Top 10 Shapley Values für Artifish-llama3.2}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    leads   & -0.36 & Kein Indikator \\
    \hline
    situation  & -0.28 & Kein Indikator   \\
    \hline
    feelings   & -0.27 & Positive oder Negative Emotionen  \\
    \hline
    Every  & -0.27 & Kein Indikator \\
    \hline
    job   & -0.24 & Kein Indikator \\
    \hline
    morning   & -0.23 & Kein Indikator \\
    \hline
    meet  & -0.23 & Kein Indikator \\
    \hline
    makes  & -0.21 & Kein Indikator \\
    \hline
    him.  & -0.20 & Personalpronomen  \\
    \hline
    1995  & -0.19 & Kein Indikator  \\
    \hline
    
    \end{tabular}
    \label{table:artifish_worst}
    \caption{Schlechtesten 10 Shapley Values für Artifish-llama3.2}
\end{table}

\subsection{Gemma 3}
Für das Modell Gemma 3 zeigt Tabelle \ref{table:gemma3} die 10 Wörter, die die höchsten Shapley-Values erreichten. Tabelle \ref{table:gemma_worst} zeigt für das Modell die 10 Wörter mit den schlechtesten Werten.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    suicidal   & 0.89 & Suizid \\
    \hline
    suicide.   & 0.76 & Suizid \\
    \hline
    die   & 0.62 & Suizid \\
    \hline
    I'll   & 0.61 & Personalpronomen \\
    \hline
    “do   & 0.56 & Kein Indikator \\
    \hline
    self-inflicted  & 0.53 & Suizid \\
    \hline
    die.  & 0.49 & Suizid \\
    \hline
    not  & 0.47 & Kein Indikator \\
    \hline
    suicider  & 0.47 & Suizid \\
    \hline
    suicide  & 0.46 & Suizid \\
    \hline
    
    \end{tabular}
    \label{table:gemma3}
    \caption{Top 10 Shapley Values für Gemma 3}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    job   & -0.48 & Kein Indikator \\
    \hline
    disappointing  & -0.38 & Negative Emotionen   \\
    \hline
    love.   & -0.36 & Positive Emotionen \\
    \hline
    Every  & -0.34 & Kein Indikator \\
    \hline
    meet   & -0.28 & Kein Indikator \\
    \hline
    crime   & -0.27 & Kein Indikator \\
    \hline
    leads  & -0.26 & Kein Indikator \\
    \hline
    knows  & -0.25 & Kein Indikator \\
    \hline
    list.  & -0.24 & Kein Indikator  \\
    \hline
    love  & -0.21 & Positive Emontionen  \\
    \hline
    
    \end{tabular}
    \label{table:gemma_worst}
    \caption{Schlechtesten 10 Shapley Values für Gemma 3}
\end{table}

\subsection{Llama3.2}
Für das Modell Llama3.2 zeigt Tabelle \ref{table:llama3} die 10 Wörter, die die höchsten Shapley-Values erreichten. Tabelle \ref{table:llama3_worst} zeigt für das Modell die 10 Wörter mit den schlechtesten Werten.

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    911. & 0.63 & Kein Indikator \\
    \hline
    injury & 0.51 & Kein Indikator \\
    \hline
    hurts & 0.39 & Kein Indikator \\
    \hline
    leads  & 0.38 & Kein Indikator \\
    \hline
    day.   & 0.37 & Kein Indikator \\
    \hline
    notice.  & 0.36 & Kein Indikator \\
    \hline
    Life  & 0.33 & Kein Indikator \\
    \hline
    live  & 0.31 & Kein Indikator \\
    \hline
    living  & 0.30 & Kein Indikator \\
    \hline
    not  & 0.28 & Kein Indikator \\
    \hline
    
    \end{tabular}
    \label{table:llama3}
    \caption{Top 10 Shapley Values für Llama3.2}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    Wort & Shapley-Value & Indikator \\
    \hline
    kill   & -0.76 & Suizid \\
    \hline
    suicide  & -0.34 & Suizid \\
    \hline
    help   & -0.34 & Kein Indikator \\
    \hline
    suicide.  & -0.33 & Suizid \\
    \hline
    die   & -0.32 & Suizid \\
    \hline
    methods   & -0.31 & Suizid \\
    \hline
    call  & -0.28 & Kein Indikator \\
    \hline
    plan  & -0.25 & Kein Indikator \\
    \hline
    suicider & -0.24 & Suizid  \\
    \hline
    here, & -0.24 & Kein Indikator \\
    \hline
    
    \end{tabular}
    \label{table:llama3_worst}
    \caption{Schlechtesten 10 Shapley Values für Llama3.2}
\end{table}

\end{document}
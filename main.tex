% !TEX encoding = UTF-8 Unicode
% !!!  THIS FILE IS UTF-8 !!!
% !!!  MAKE SURE YOUR LaTeX Editor IS CONFIGURED TO USE UTF-8 !!!

% Computational and Data Science Course Paper LaTeX Template
% University of Applied Sciences of the Grisons
% ---------------------------------------------------------------
% Author: Corsin Capol corsin.capol@fhgr.ch
% ---------------------------------------------------------------

%-------------------------
% header
% ------------------------
\documentclass[a4paper,12pt]{scrartcl}
\linespread {1.25}

%-------------------------
% packages and config
% ------------------------
\input{packages_and_configuration}

%-------------------------
% document begin
%-------------------------
\begin{document}

%-------------------------
% title
%-------------------------
\input{title}

\section{Introduction}

Die Erfolge in der Suizidprävention sind seit Jahren stagnierend (404 error). Ein Suizid ist nicht nur ein Verlust einer einzelnen Person, sondern hat auch weitreichende schwere Einflüsse auf die Hinterbliebenen. Daher ist es wichtig, die Forschung in diesem Bereich voran zu treiben, um Erkentnisse zu gewinnen, wie eine geplante Selbsttötung erkannt und verhindert werden kann.

Es gibt einige Versuche, mit verschiedenen Lösungsstrategien einen Algorithmus zu entwickeln, der vorhersagen kann, welche Menschen Suizidgefährdet sind(Words of Suicide, Predicting the Risk of Suicide). Allerdings zeigen diese Studien oft, dass die Genauigkeit eher schwach sind. Hinzu kommt, dass Suizid ein selten auftretendes Verhalten ist (404 error). Das bedeutet, dass wenn 1 aus 100 Personen suizidgefährded ist, und ein Modell mit 99\% Genauigkeit Suizide vorhersagen kann, so würde das Modell zwar diese eine aus 100 Personen erkennen, aber eben auch 9 weitere Personen, die nicht suizidgefährdend sind.

Da sich Suizid auch in der Sprache äussern kann (Words of Suicide), stellt sich die Frage, ob die neuen grossen Sprachmodelle (LLM) bei der Erkennung von Suizidgefährdeden hilfreich sein können. Anders als traditionelle Machinelearning Algorithmen wie Support Vector Machines oder Lineare Regressionen sind LLMs auf die Verarbeitung und Interpretation von Sprache spezialisiert.

Da die LLMs in sehr vielen Bereichen Einzug erhalten haben, hat die Europäische Union den EU Artificial Intelligence Act verabschiedet. Artikel 1 dieses Acts soll den Einsatz von Artificial Intelligence (AI) Systemen regulieren mit dem Ziel, die Inovation durch AI zu fördern und gleichzeitig negativen Folgen von AI entgegenzuwirken \cite{eu_ai_act_2024}. Den Einsatz eines AI Systems zur Erkennung von Suizidgefährdeten würde durch Annex III, Paragraph 5 a und d als ein <High Risk AI System> eigestuft. Das bedeutet, dass selbst wenn LLMs perfekt Suizidgefährdungen früherkennen können, dürfen sie nur eingesetzt werden, wenn sie den Auflagen entsprechen.

Zu diesen Auflagen gehört auch, dass das Modell interpretierbar sein muss. Dass heisst, eine menschliche Person muss nachvollziehen können, warum das System bei einer Person anschlägt und bei einer anderen nicht. Die Erklärbarkeit von LLMs ist aber noch immer ein ungeklärtes Feld der Forschung (High Stakes, XAI). (ExplainShapley) hat ein System vorgeschlagen, dass mit Hilfe der Shapley Values zu erklären versucht, welche Wörter des Inputs zum Output beigetragen haben.

In dieser Arbeit wird 


\section{Research Question}

\section{Methodology}
\section{Results}

\section{Diskussion}

%-------------------------
% literature
%-------------------------
\bibliography{jabref}

\end{document}